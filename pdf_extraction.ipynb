{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule-based extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 4300-protocol-version-4.pdf\n",
      "Processing: 4303-protocol-version-3.pdf\n",
      "Processing: 4309-protocol-version-3.0.pdf\n",
      "Processing: 4316-protocol-version-4 - final.pdf\n",
      "Processing: 4338-protocol-version-4.0.pdf\n",
      "Processing: 4373-protocol-version-4.0.pdf\n",
      "Processing: 4378-protocol-version-3.0.pdf\n",
      "Processing: 4379-protocol-version-4.0.pdf\n",
      "Processing: 4386-protocol-version-1.0.pdf\n",
      "Processing: 4451-protocol-version-1.0.pdf\n",
      "Processing: 4462-protocol-version-6.pdf\n",
      "Processing: 4486-protocol-version-7.0.pdf\n",
      "Processing: 4492-protocol-version-3.pdf\n",
      "Processing: 4518-protocol-version-4.pdf\n",
      "Processing: 4601-protocol  version 4.0.pdf\n",
      "Processing: 4669-protocol-version-7.0.pdf\n",
      "Processing: 4748-protocolv3.pdf\n",
      "Processing: 4774-protocol-v3.0.pdf\n",
      "Processing: 4885-protocol-version-4.pdf\n",
      "Processing: 4921-protocol-version-3.0.pdf\n",
      "Processing: 4924-protocol-v1.0.pdf\n",
      "Processing: 7611 protocol v1.0_22FEB2024.pdf\n",
      "Processing: 7663-protocol-version-1.0.pdf\n",
      "Processing: nn1218-4357.pdf\n",
      "Processing: nn1436-4479.pdf\n",
      "Processing: nn1436-4480.pdf\n",
      "Processing: nn1436-4570.pdf\n",
      "Processing: nn1436-4571.pdf\n",
      "Processing: nn1436-4572.pdf\n",
      "Processing: nn1436-4909.pdf\n",
      "Processing: nn1436-7724.pdf\n",
      "Processing: nn1471-4612.pdf\n",
      "Processing: nn1471-4752.pdf\n",
      "Processing: nn1535-4591.pdf\n",
      "Processing: nn1535-4592.pdf\n",
      "Processing: nn1535-4710.pdf\n",
      "Processing: nn1535-4988.pdf\n",
      "Processing: nn6018-4889.pdf\n",
      "Processing: nn6018-4951.pdf\n",
      "Processing: nn6019-4940.pdf\n",
      "Processing: nn6022-7683.pdf\n",
      "Processing: nn6435-4697.pdf\n",
      "Processing: nn6435-4749.pdf\n",
      "Processing: nn6435-4826.pdf\n",
      "Processing: nn6535-7519.pdf\n",
      "Processing: nn6537-7650.pdf\n",
      "Processing: nn6582-4838.pdf\n",
      "Processing: nn7088-4595.pdf\n",
      "Processing: nn7533-4470.pdf\n",
      "Processing: nn7533-7587.pdf\n",
      "Processing: nn7535-7702.pdf\n",
      "Processing: nn7535-7703.pdf\n",
      "Processing: nn7535-7704.pdf\n",
      "Processing: nn7535-7807.pdf\n",
      "Processing: nn7535-7976.pdf\n",
      "Processing: nn7614-7656.pdf\n",
      "Processing: nn7769-4516.pdf\n",
      "Processing: nn7769-4532.pdf\n",
      "Processing: nn7769-4992.pdf\n",
      "Processing: nn7999-4670.pdf\n",
      "Processing: nn8022-4179.pdf\n",
      "Processing: nn8640-4469.pdf\n",
      "Processing: nn9388-4895.pdf\n",
      "Processing: nn9388-7637.pdf\n",
      "Processing: nn9388-7700.pdf\n",
      "Processing: nn9389-4606.pdf\n",
      "Processing: NN9389-4679-protocol-3.0.pdf\n",
      "Processing: nn9389-4680.pdf\n",
      "Processing: nn9389-4681.pdf\n",
      "Processing: nn9389-4682.pdf\n",
      "Processing: nn9487-5022.pdf\n",
      "Processing: nn9487-7573.pdf\n",
      "Processing: nn9487-7612.pdf\n",
      "Processing: nn9487-7980.pdf\n",
      "Processing: nn9490-7678.pdf\n",
      "Processing: nn9500-4620.pdf\n",
      "Processing: nn9500-4621.pdf\n",
      "Processing: nn9500-4796.pdf\n",
      "Processing: nn9500-4932.pdf\n",
      "Processing: nn9501-4869.pdf\n",
      "Processing: nn9501-5006.pdf\n",
      "Processing: nn9515-7675.pdf\n",
      "Processing: nn9535-4430.pdf\n",
      "Processing: nn9535-4533.pdf\n",
      "Processing: NN9535-4801 protocol v2.0.pdf\n",
      "Processing: nn9535-4820.pdf\n",
      "Processing: nn9535-7560.pdf\n",
      "Processing: nn9536-4576.pdf\n",
      "Processing: nn9536-4578.pdf\n",
      "Processing: nn9536-4707.pdf\n",
      "Processing: nn9536-4741.pdf\n",
      "  Missing sections: clinical_lab\n",
      "Processing: nn9536-4999.pdf\n",
      "Processing: nn9536-7545.pdf\n",
      "Processing: nn9541-4922.pdf\n",
      "Processing: nn9541-4923.pdf\n",
      "Processing: nn9541-4945.pdf\n",
      "Processing: nn9541-5015.pdf\n",
      "Processing: nn9650-5027.pdf\n",
      "Processing: nn9662-7694sad.pdf\n",
      "Processing: nn9775-4708b.pdf\n",
      "Processing: nn9838-4615.pdf\n",
      "Processing: nn9838-4672.pdf\n",
      "Processing: nn9838-4695.pdf\n",
      "Processing: nn9838-4862.pdf\n",
      "Processing: nn9838-7832.pdf\n",
      "Processing: nn9838-8259.pdf\n",
      "Processing: nn9904-4825sad.pdf\n",
      "Processing: nn9924-4556.pdf\n",
      "Processing: nn9924-4891.pdf\n",
      "Processing: nn9924-4977.pdf\n",
      "Processing: nn9932-4737.pdf\n",
      "Processing: nn9932-4861.pdf\n",
      "Processing: nn9932-4873.pdf\n",
      "Processing: Protocol  4468-trial-protocol-final-version-1.0.pdf\n",
      "Processing: Protocol  4569 protocol vers 4.0.pdf\n",
      "Processing: Protocol  4663-protocol-version-3.0.pdf\n",
      "Processing: Protocol  4738 protocol v2.0.pdf\n",
      "Processing: Protocol  NN8022-4392 Trial protocol ver.4.0.pdf\n",
      "Processing: Protocol  NN9838-4609 protocol version 7.0.pdf\n",
      "Processing: Protocol  REAL4 protocol v10.pdf\n",
      "Processing: Protocol Amendment  NN9838-4608 protocol v5.0.pdf\n",
      "Processing: Protocol Amendment  NN9838-4762 protocol v2.0.pdf\n",
      "Processing: protocol-4706-version-1.0.pdf\n",
      "Processing: Trial 4662 protocol_v3.0.pdf\n",
      "Processing: _ Protocol  4910 protocol.pdf\n",
      "Processing: _ Protocol  4954 protocol v.1.0.pdf\n",
      "Processing: _ Protocol Amendment  protocol version 2.0 (1).pdf\n",
      "✅ JSONL file created: fine_tuning_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from pdfplumber.utils import extract_text, get_bbox_overlap, obj_to_bbox\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pdb\n",
    "\n",
    "def regex_ignore_whitespace(pattern):\n",
    "    # Split the pattern into words and rejoin them allowing any amount of whitespace\n",
    "    words = pattern.split()\n",
    "    return r\"\\s*\".join(map(re.escape, words))\n",
    "\n",
    "# Header removal\n",
    "def remove_header_chars(page, header_height=100):\n",
    "    return [char for char in page.chars if char['top'] > header_height]\n",
    "\n",
    "# This function returns the cleaned page text (with header removed)\n",
    "def get_cleaned_page_text(page):\n",
    "    chars = remove_header_chars(page, header_height=100)\n",
    "    \n",
    "    # Remove residual header info (e.g. \"Page xx of ...\")\n",
    "    end_header = None\n",
    "    line_threshold = 7  # if the top coordinate increases by more than 7,  assume a new line\n",
    "    for k in range(len(chars) - 3):\n",
    "        if (\"P\" in chars[k][\"text\"] and \"a\" in chars[k+1][\"text\"] and\n",
    "            \"g\" in chars[k+2][\"text\"] and \"e\" in chars[k+3][\"text\"]):\n",
    "            initial_top = chars[k][\"top\"]\n",
    "            i = k\n",
    "            while i < len(chars) - 1 and end_header is None:\n",
    "                # If I see \"of\" following some characters\n",
    "                if \"o\" in chars[i][\"text\"] and \"f\" in chars[i+1][\"text\"]:\n",
    "                    for j in range(i+2, len(chars)):\n",
    "                        # Check if I've encountered a new line based on vertical position change\n",
    "                        if chars[j][\"top\"] - initial_top > line_threshold:\n",
    "                            end_header = j - 1\n",
    "                            break\n",
    "                        # Alternatively, if the text is not numeric and not whitespace, mark the end\n",
    "                        if not (chars[j][\"text\"].isnumeric() or chars[j][\"text\"].isspace()):\n",
    "                            end_header = j - 1\n",
    "                            break\n",
    "                i += 1\n",
    "            if end_header is not None:\n",
    "                # Remove header characters (pop in reverse order)\n",
    "                for i in range(end_header, -1, -1):\n",
    "                    chars.pop(i)\n",
    "            break\n",
    "\n",
    "    # Process tables: filter out table regions and append table data as markdown\n",
    "    for table in page.find_tables():\n",
    "        cropped = page.crop(table.bbox)\n",
    "        # Check if there are any characters in the cropped area\n",
    "        if not cropped.chars:\n",
    "            continue  # Skip this table if no characters found \n",
    "        first_table_char = cropped.chars[0]\n",
    "        filtered_page = page.filter(lambda obj: get_bbox_overlap(obj_to_bbox(obj), table.bbox) is None)\n",
    "        chars = filtered_page.chars\n",
    "        df = pd.DataFrame(table.extract())\n",
    "        markdown = df.to_markdown(index=False)\n",
    "        table_char = first_table_char.copy()\n",
    "        table_char[\"text\"] = markdown\n",
    "        chars.append(table_char)\n",
    "\n",
    "    page_text = extract_text(chars, layout=True, y_tolerance=6)\n",
    "    page_text = page_text.replace(\"\", \"•\").replace(\"\\uf0b7\", \"•\")\n",
    "    return page_text\n",
    "\n",
    "\n",
    "\n",
    "# Section detection patterns \n",
    "# Endpoints section\n",
    "endpoints_sections = [\n",
    "    \"2 study objectives\",\n",
    "    \"2. study objectives\",\n",
    "    \"3 study endpoints\",\n",
    "    \"3 objectives and endpoints\",\n",
    "    \"3 objectives, endpoints and estimands\",\n",
    "    \"3 objectives, endpoints and estimand\",\n",
    "    \"3 objectives, endpoints\",\n",
    "    \"3. study endpoints\",\n",
    "    \"3. objectives and endpoints\",\n",
    "    \"3. objectives, endpoints and estimands\",\n",
    "    \"3. objectives, endpoints and estimand\",\n",
    "    \"3. objectives, endpoints\",\n",
    "    \"4 objectives and endpoints\",\n",
    "    \"4 objective(s) and endpoint(s)\",\n",
    "    \"4. objectives and endpoints\",\n",
    "    \"4. objective(s) and endpoint(s)\",\n",
    "    \"4.1 objective(s)\",\n",
    "    \"4 objective(s) and endpoint(s)\",\n",
    "    \"4. objective(s) and endpoint(s)\",\n",
    "    \"4 objective(s) and endpoint(s)\",\n",
    "    \"4 objective (s) and endpoint (s)\",\n",
    "    \"4 objective.*?endpoint\",\n",
    "    \"5 objectives, endpoints and estimands\",\n",
    "    \"5. objectives, endpoints and estimands\",\n",
    "    \"8 research question and objectives\",\n",
    "    \"8. research question and objectives\"\n",
    "]\n",
    "\n",
    "post_endpoints_sections = [\n",
    "    \"3 study description\",\n",
    "    \"3. study description\",\n",
    "    \"4 study design\",\n",
    "    \"4 trial design\",\n",
    "    \"4. study design\",\n",
    "    \"4. trial design\",\n",
    "    \"5 trial design\",\n",
    "    \"5. trial design\",\n",
    "    \"6 trial design\",\n",
    "    \"6. trial design\",\n",
    "    \"9.2 setting\",\n",
    "    \"9.2. setting\"\n",
    "]\n",
    "\n",
    "# Statistics section\n",
    "stats_sections = [\n",
    "    \"6 statistical methods\",\n",
    "    \"6. statistical methods\",\n",
    "    \"9 statistics\",\n",
    "    \"9 statistical considerations\",\n",
    "    \"9.7.2 statistical methods\",\n",
    "    \"9.7.2. statistical methods\",\n",
    "    \"9. statistics\",\n",
    "    \"9. statistical considerations\",\n",
    "    \"10 statistical considerations\",\n",
    "    \"10. statistical considerations\",\n",
    "    \"11 statistical considerations\",\n",
    "    \"11. statistical considerations\",\n",
    "    \"16 statistical considerations\",\n",
    "    \"16. statistical considerations\",\n",
    "    \"17 statistical considerations\",\n",
    "    \"17. statistical considerations\"\n",
    "]\n",
    "\n",
    "post_stats_sections = [\n",
    "    \"7 adverse event collection\",\n",
    "    \"7 adverse event (ae) reporting\",\n",
    "    \"7. adverse event collection\",\n",
    "    \"7. adverse event (ae) reporting\",\n",
    "    \"9.8 quality control\",\n",
    "    \"10 supporting documentation and operational considerations\",\n",
    "    \"10 data management and record keeping\",\n",
    "    \"10. supporting documentation and operational considerations\",\n",
    "    \"10. data management and record keeping\",\n",
    "    \"11 references\",\n",
    "    \"11 appendices\",\n",
    "    \"11. references\",\n",
    "    \"11. appendices\",\n",
    "    \"12 appendices\",\n",
    "    \"12. appendices\",\n",
    "    \"17 ethics\",\n",
    "    \"17. ethics\",\n",
    "    \"18 ethics\",\n",
    "    \"18. ethics\"\n",
    "]\n",
    "\n",
    "# Clinical laboratory section\n",
    "clinical_lab_sections = [\n",
    "    \"10.2 Appendix 2: Clinical laboratory tests\",\n",
    "    \"Appendix 2 Clinical laboratory tests\",\n",
    "    \"Appendix 2: Clinical laboratory tests\",\n",
    "    \"Appendix 2 Clinical laboratory assessments\",\n",
    "    \"Appendix 2: Clinical laboratory assessments\",\n",
    "    \"8.5.17 Laboratory assessments\",\n",
    "    \"8.5 Laboratory assessments\",\n",
    "    \"8.3.11 Laboratory assessments for safety\",\n",
    "    \"8.4.6 Laboratory assessments for safety\",\n",
    "    \"8.5.7 Blood samples for safety assessments\",\n",
    "]\n",
    "\n",
    "# Special sections for clinical lab cases where the Appendix word is not readable. For this case, make sure that the stats section has been passed \n",
    "clinical_lab_special_sections = [\n",
    "    \"Clinical laboratory tests\"\n",
    "    ]\n",
    "\n",
    "\n",
    "post_clinical_lab_sections = [\n",
    "    \"8.2.7 Pregnancy testing\",\n",
    "    \"10.3 Appendix 3: Adverse Events and Serious Adverse Events: Definitions and procedures for recording, evaluating, follow-up, and reporting\",\n",
    "    \"9.6 Pharmacokinetics\",\n",
    "    \"Appendix 3 Trial governance considerations\",\n",
    "    \"8.2.6 Pregnancy testing\",\n",
    "    \"10.3 Appendix 3: Adverse events: Definitions and procedures for recording, evaluation, follow-up, and reporting\",\n",
    "    \"8.5.18 Body weight and height\",\n",
    "    \"8.9 Subject compliance\",\n",
    "    \"8.3.12 Pregnancy testing\",\n",
    "    \"8.6 Other assessments\",\n",
    "    \"8.4.7 Pregnancy testing\",\n",
    "    \"Appendix 3 Trial governance considerations\",\n",
    "    \"9.4.6 Immunogenicity assessments\",\n",
    "    \"9.5 Pharmacokinetics\",\n",
    "    \"9.4.4 Eye examination\",\n",
    "    \"9.4.8 Immunogenicity assessments\",\n",
    "    \"9.6.9 Immunogenicity assessments\",\n",
    "    \"8.2.5 Self-measured plasma glucose\",\n",
    "    \"9.4.6 Injection site reactions\",\n",
    "    \"9.4.5 Immunogenicity assessments\",\n",
    "    \"8.3 Adverse events and serious adverse events\",\n",
    "    \"8.3 Adverse events and other safety reporting\",\n",
    "    \"8.2.5 Pregnancy testing\",\n",
    "    \"8.2.5 Injection site reactions\",\n",
    "    \"8.5.8 Anti-liraglutide antibodies\",\n",
    "    \"Trial governance considerations\",\n",
    "    \"Appendix 3: Adverse Events and Serious Adverse Events: Definitions and procedures for recording, evaluating, follow-up, and reporting\",\n",
    "    \"Appendix 3: Adverse events: Definitions and procedures for recording, evaluation, follow-up, and reporting\"\n",
    "\n",
    "]\n",
    "\n",
    "# Adverse events section\n",
    "ae_sections = [\n",
    "    \"10.3.3 Description of AEs requiring additional data collection and other events requiring collection of additional information\",\n",
    "    \"Table 8-1 AEs requiring additional data collection (serious and non-serious AEs)\",\n",
    "    \"Description of AEs requiring additional data collection (via specific event form)\",\n",
    "    \"10.3.3 Description of AEs requiring additional data collection\",\n",
    "    \"12.1.5 Adverse events requiring additional data collection\",\n",
    "    \"8.4.1.2 Adverse events requiring additional data collection\",\n",
    "    \"8.4.1.1 Adverse events requiring additional data collection\",\n",
    "    \"Table 9-1 AEs requiring additional data collection\",\n",
    "    \"Table 9-1 AEs requiring additional data collection (via specific event form) and events for adjudication\",\n",
    "    \"Table 9-1 AEs requiring additional data collection (via specific event form)\",\n",
    "    \"Table 8-1 AEs requiring additional data collection\",\n",
    "    \"Table 8-2 AEs requiring additional data collection and other events requiring collection of additional information\",\n",
    "    \"Table 8-1 AEs requiring additional data collection and other events requiring additional data collection\",\n",
    "    \"Table 8-1 AEs requiring additional data collection, events for adjudication and other events requiring collection of additional information\",\n",
    "    \"Table 8-1 AEs requiring additional data collection (serious and non-serious AEs) and AESIs\",\n",
    "    \"Table 8-3 AEs requiring additional data collection (serious and non-serious AEs) and AESIs\",\n",
    "    \"Table 8-2 AEs requiring additional data collection (serious and non-serious AEs) and events for adjudication\",\n",
    "    \"Table 6 AEs requiring additional data collection\",\n",
    "    \"Table 8-1 AEs requiring additional data collection and other events requiring collection of additional information\",\n",
    "    \"Table 8-1 Adverse events requiring additional data collection\",\n",
    "    \"Table 8-2 AEs requiring additional data collection, events for adjudication, AESIs and other events requiring collection of additional information\",\n",
    "    \"Table 8-1 AEs requiring additional data collection and AESIs\",\n",
    "    \"8.6.3 Adverse events requiring specific event forms in the Ecrf\",\n",
    "    \"Table 8-4 AEs requiring additional data collection\",\n",
    "    '\"Table 8-2 AEs requiring additional data collection and other events requiring collection of additional information\"',\n",
    "    \"Table 8-3 AEs requiring additional data collection and other events requiring collection of additional information\",\n",
    "    \"Table 9-1 AEs requiring additional data collection (via specific event forms)\",\n",
    "    \"Table 8-1 Events requiring additional data collection\",\n",
    "    \"Table 8-2 AEs requiring additional data collection, events for adjudication, and other events requiring collection of additional information\",\n",
    "    \"Table 10-2 AEs requiring additional data collection (via specific event form)\",\n",
    "    \"Table 8-2 AEs requiring additional data collection and events for adjudication\",\n",
    "    \"Table 4 AEs requiring additional data collection (via specific event form)\",\n",
    "    \"Table 8-1 AEs requiring additional data collection and events for adjudication in main phase\"\n",
    "]\n",
    "\n",
    "post_ae_sections = [\n",
    "    \"10.3.4 Recording and follow-up of AE and/or SAE\",\n",
    "    \"8.3.1 Time period and frequency for collecting AE information\",\n",
    "    \"AE and SAE recording\",\n",
    "    \"8.3.1 Time period and frequency for collecting AE and SAE information\",\n",
    "    \"12.1.6 Technical complaints\",\n",
    "    \"8.4.2 Hypoglycaemic episodes\",\n",
    "    \"8.4.2 Physical examination\",\n",
    "    \"9.2.1.1 Events for adjudication\",\n",
    "    \"9.2.1.1 Event for adjudication\",\n",
    "    \"9.2.2 Method of detecting AEs and SAEs\",\n",
    "    \"9.4.2 Method of detecting AEs and SAEs\",\n",
    "    \"8.4.1 Time period and frequency for collecting AE and SAE information\",\n",
    "    \"8.5.1 Time period and frequency for collecting AE and SAE information\",\n",
    "    \"8.4.1 Time period and frequency for collecting AE information\",\n",
    "    \"8.3.1 Time period and frequency for collecting adverse event information\",\n",
    "    \"8.7 Other assessments\",\n",
    "    \"8.5.1 Time period and frequency for collecting AE information\",\n",
    "    \"9.2.1 Time period and frequency for collecting AE and SAE information\",\n",
    "    \"10.2.2 Method of detecting AEs and SAEs\",\n",
    "    \"9.2.2 Method of detecting AEs and SAEs\",\n",
    "    \"8.4.1.3 Assessments in case of suspicion of acute pancreatitis\"\n",
    "]\n",
    "\n",
    "def process_pdf_sections(pdf_path):\n",
    "    pdf = pdfplumber.open(pdf_path)\n",
    "    collected_text = []  #  store extracted text\n",
    "    collecting_section = None  # can be: endpoints, statistics, clinical_lab, adverse_events\n",
    "    toc_skipped = False  # flag to skip TOC pages\n",
    "    endpoints_passed = False  # flag to indicate I've passed the endpoints section\n",
    "    stats_passed = False      # flag to indicate I've passed the statistics section\n",
    "\n",
    "    # Dictionary to track if sections were found\n",
    "    found_sections = {\"endpoints\": False, \"statistics\": False, \"clinical_lab\": False, \"adverse_events\": False}\n",
    "\n",
    "    for page in pdf.pages:\n",
    "        cleaned_text = get_cleaned_page_text(page)\n",
    "        text_lower = cleaned_text.lower()\n",
    "\n",
    "        # Skip TOC pages until a marker is found (using post_stats_sections as proxy)\n",
    "        if not toc_skipped:\n",
    "            for pattern in post_stats_sections:\n",
    "                if re.search(regex_ignore_whitespace(pattern), text_lower, re.IGNORECASE):\n",
    "                    toc_skipped = True\n",
    "                    break\n",
    "            if not toc_skipped:\n",
    "                continue\n",
    "            else:\n",
    "                continue  # skip the triggering page\n",
    "\n",
    "        page_to_append = None\n",
    "\n",
    "        # If not already in a section, check for a section start marker in order.\n",
    "        if collecting_section is None:\n",
    "            # Check endpoints markers\n",
    "            for pattern in endpoints_sections:\n",
    "                m = re.search(regex_ignore_whitespace(pattern), text_lower, re.IGNORECASE)\n",
    "                if m:\n",
    "                    collecting_section = \"endpoints\"\n",
    "                    collected_text.append(\"### Endpoints Section\\n\")\n",
    "                    page_to_append = cleaned_text[m.start():]\n",
    "                    endpoints_passed = True\n",
    "                    found_sections[\"endpoints\"] = True\n",
    "                    break\n",
    "            # Check statistics markers if endpoints not found\n",
    "            if collecting_section is None:\n",
    "                for pattern in stats_sections:\n",
    "                    m = re.search(regex_ignore_whitespace(pattern), text_lower, re.IGNORECASE)\n",
    "                    if m:\n",
    "                        collecting_section = \"statistics\"\n",
    "                        collected_text.append(\"### Statistical Considerations Section\\n\")\n",
    "                        page_to_append = cleaned_text[m.start():]\n",
    "                        stats_passed = True\n",
    "                        found_sections[\"statistics\"] = True\n",
    "                        break\n",
    "            # Check clinical lab markers if endpoints have passed\n",
    "            if collecting_section is None and endpoints_passed:\n",
    "                for pattern in clinical_lab_sections:\n",
    "                    m = re.search(regex_ignore_whitespace(pattern), text_lower, re.IGNORECASE)\n",
    "                    if m:\n",
    "                        collecting_section = \"clinical_lab\"\n",
    "                        collected_text.append(\"### Clinical Laboratory Section\\n\")\n",
    "                        page_to_append = cleaned_text[m.start():]\n",
    "                        found_sections[\"clinical_lab\"] = True\n",
    "                        break\n",
    "            # Check adverse events markers if endpoints have passed\n",
    "            if collecting_section is None and endpoints_passed:\n",
    "                for pattern in ae_sections:\n",
    "                    m = re.search(regex_ignore_whitespace(pattern), text_lower, re.IGNORECASE)\n",
    "                    if m:\n",
    "                        collecting_section = \"adverse_events\"\n",
    "                        collected_text.append(\"### Adverse Events Section\\n\")\n",
    "                        page_to_append = cleaned_text[m.start():]\n",
    "                        found_sections[\"adverse_events\"] = True\n",
    "                        break\n",
    "            # Check clinical lab special cases if statistics have passed and still not found\n",
    "            if collecting_section is None and stats_passed:\n",
    "                for pattern in clinical_lab_special_sections:\n",
    "                    m = re.search(regex_ignore_whitespace(pattern), text_lower, re.IGNORECASE)\n",
    "                    if m:\n",
    "                        collecting_section = \"clinical_lab\"\n",
    "                        collected_text.append(\"### Clinical Laboratory Section\\n\")\n",
    "                        page_to_append = cleaned_text[m.start():]\n",
    "                        found_sections[\"clinical_lab\"] = True\n",
    "                        break\n",
    "        # If already inside a section, check for an end-of-section marker.\n",
    "        if collecting_section is not None:\n",
    "            end_patterns = []\n",
    "            if collecting_section in [\"endpoints\", \"statistics\"]:\n",
    "                end_patterns = post_endpoints_sections + post_stats_sections\n",
    "            elif collecting_section == \"clinical_lab\":\n",
    "                end_patterns = post_clinical_lab_sections\n",
    "            elif collecting_section == \"adverse_events\":\n",
    "                end_patterns = post_ae_sections\n",
    "\n",
    "            for pattern in end_patterns:\n",
    "                m_end = re.search(regex_ignore_whitespace(pattern), text_lower, re.IGNORECASE)\n",
    "                if m_end:\n",
    "                    page_to_append = cleaned_text[:m_end.start()]\n",
    "                    collecting_section = None\n",
    "                    break\n",
    "\n",
    "            # If no end marker found, include the entire page.\n",
    "            if collecting_section is not None and page_to_append is None:\n",
    "                page_to_append = cleaned_text\n",
    "\n",
    "        if page_to_append is not None:\n",
    "            collected_text.append(page_to_append.strip())\n",
    "\n",
    "    pdf.close()\n",
    "    extracted = \"\\n\\n\".join(collected_text) if collected_text else \"Not Found\"\n",
    "    return extracted, found_sections\n",
    "\n",
    "# iterate through all files and write JSONL \n",
    "folder = os.path.join(\"data\", \"included_protocols_after_place_revision\")\n",
    "output_jsonl = \"fine_tuning_data.jsonl\"\n",
    "\n",
    "with open(output_jsonl, \"w\", encoding=\"utf-8\") as out_f:\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            print(\"Processing:\", filename)\n",
    "            pdf_path = os.path.join(folder, filename)\n",
    "            extracted_text, found_sections = process_pdf_sections(pdf_path)\n",
    "\n",
    "            # Check if any required section is not found\n",
    "            missing = [section for section, found in found_sections.items() if not found]\n",
    "            if missing:\n",
    "                print(\"  Missing sections:\", \", \".join(missing))\n",
    "            record = {\"filename\": filename, \"text\": extracted_text}\n",
    "            out_f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"JSONL file created: {output_jsonl}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Camelot env",
   "language": "python",
   "name": "pdfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
